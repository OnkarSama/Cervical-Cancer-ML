{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8970652,"sourceType":"datasetVersion","datasetId":5400611},{"sourceId":8970921,"sourceType":"datasetVersion","datasetId":5400786}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#invite people for the Kaggle party\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy.stats import norm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\n\nimport random as rd\nimport math\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/cervical-cancer-data/risk_factors_cervical_cancer.csv')\ndf_2 = pd.read_csv('/kaggle/input/behaviour-risk/sobar-72.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(900)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['STDs: Time since first diagnosis'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['STDs: Time since first diagnosis'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=['STDs: Time since first diagnosis','STDs: Time since last diagnosis'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr=[]\nfor i in df.itertuples():\n    tup = i\n    for j in tup:\n        if j == '?':\n            arr.append(tup[0])\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_df = pd.DataFrame(arr, columns=['indices'])\nindex_arr = index_df['indices'].unique().flatten()\n\ndf_cleaned = df.drop(index_arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr=[]\nfor i in df_cleaned.itertuples():\n    tup = i\n    for j in tup:\n        if j == '?':\n            print(tup[0])\n            arr.append(tup[0])\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned['STDs:HPV'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned['Num of pregnancies'].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned['Num of pregnancies'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 1: Replace '?' with NaN\n# df['Num of pregnancies'].replace('?', 'np.nan', inplace=True)\n\n# # Step 2: Convert the column to numeric, forcing errors to NaN\n# df['Num of pregnancies'] = pd.to_numeric(df['Num of pregnancies'], errors='coerce')\n\n# df['Num of pregnancies'].describe()\n\n# # # Step 3: Calculate the mean, ignoring NaN values\n# mean_value = df['Num of pregnancies'].median()\n\n# print(mean_value)\n\ndf_cleaned['Hormonal Contraceptives'].unique()\n\n# Hormonal Contraceptives","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned['Hormonal Contraceptives (years)'].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#     feature_cols = ['Age', 'Number of sexual partners', 'First sexual intercourse',\n#        'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)',\n#        'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD',\n#        'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis',\n#        'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis',\n#        'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis',\n#        'STDs:pelvic inflammatory disease', 'STDs:genital herpes',\n#        'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV',\n#        'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis',\n#        'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Dx', 'Hinselmann', 'Schiller',\n#        'Citology', 'Biopsy']\n# # Step 2: Calculate the correlation matrix (it will automatically ignore NaN values)\n# corr_matrix = df_cleaned[feature_cols].astype(float).corr()\n\n# # Step 3: Plot the heatmap\n# corr_matrix.style.background_gradient()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_cleaned[df_cleaned['Dx']==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def split_data(df_total):\n    \n#     full_cancerous = df_total[df_total['Dx'] == 1]\n#     full_non_cancerous = df_total[df_total['Dx'] == 0]\n    \n#     mid_cancerous = len(full_cancerous) // 2\n#     mid_non_cancerous = len(full_non_cancerous) // 2\n    \n#     cancerous1 = full_cancerous.iloc[:mid_cancerous]\n#     cancerous2 = full_cancerous.iloc[mid_cancerous:]\n#     non_cancerous1 = full_non_cancerous.iloc[:mid_non_cancerous]\n#     non_cancerous2 = full_non_cancerous.iloc[mid_non_cancerous:]\n    \n#     return cancerous1.reset_index(drop=True), cancerous2.reset_index(drop=True), non_cancerous1.reset_index(drop=True), non_cancerous2.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_random_indices(num_of_random,len_of_df):\n    \n    indices = []\n    \n    for i in range(num_of_random):\n        indices.append(rd.randint(0,len_of_df-1))\n    \n    return indices","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2):\n    \n#     random_nc = pd.DataFrame()\n#     X_train = pd.DataFrame()\n#     X_test = pd.DataFrame()\n#     Y_train = pd.DataFrame()\n#     Y_test = pd.DataFrame()\n    \n#     random_indices = get_random_indices(8,len(non_cancerous1))\n    \n#     random_nc = non_cancerous1.iloc[random_indices]\n    \n#     full_train_set = pd.concat([cancerous1,random_nc])\n    \n#     full_test_set = pd.concat([cancerous2,non_cancerous2])\n    \n#     feature_cols = ['Age', 'Number of sexual partners', 'First sexual intercourse',\n#        'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)',\n#        'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD',\n#        'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis',\n#        'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis',\n#        'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis',\n#        'STDs:pelvic inflammatory disease', 'STDs:genital herpes',\n#        'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV',\n#        'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis',\n#        'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Hinselmann', 'Schiller',\n#        'Citology', 'Biopsy']\n    \n#     X_train = full_train_set[feature_cols]\n#     Y_train = pd.concat([Y_train,full_train_set['Dx']])\n    \n#     X_test = full_test_set[feature_cols]\n#     Y_test = pd.concat([Y_test,full_test_set['Dx']])\n    \n#     return X_train.reset_index(drop=True), Y_train.reset_index(drop=True), X_test.reset_index(drop=True), Y_test.reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_coefs(X_train,Y_train):\n    \n    num_of_cols = len(X_train.columns)\n    \n    columns_names = [f'x{i+1}' for i in range(num_of_cols)] + ['intercept']\n    \n    coef_list = pd.DataFrame()\n    \n    logreg = LogisticRegression()\n\n    # fit the model with data\n    logreg.fit(X_train, Y_train)\n\n    coef_intercept = np.append(logreg.coef_.flatten(),logreg.intercept_[0])\n    \n    coef_intercept = coef_intercept.reshape(1, -1)\n    \n    coef_list = pd.DataFrame(coef_intercept, columns=columns_names)\n    \n    return coef_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def run_simulation(sim_len, df_total):\n    \n#     sim_coef_list = pd.DataFrame()\n    \n#     cancerous1, cancerous2, non_cancerous1, non_cancerous2 = split_data(df_total)\n    \n#     for i in range(sim_len):\n        \n#         X_train, Y_train, X_test, Y_test = create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2) \n        \n#         coef_list = get_coefs(X_train,Y_train)\n        \n#         sim_coef_list = pd.concat([coef_list,sim_coef_list])\n        \n#     return sim_coef_list.reset_index(drop=True), X_test, Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_coef_list, X_test, Y_test= run_simulation(100, df_cleaned)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_coef_list.head(500)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_avg_coefs_with_df(sim_coef_list):\n    # Compute the mean of each column in the DataFrame\n    avg_coefs = sim_coef_list.mean()\n    \n    # Convert the resulting Series to a NumPy array\n    avg_coefs_array = avg_coefs.to_numpy()\n    \n    # Create a DataFrame from the average coefficients\n    avg_coefs_df = pd.DataFrame([avg_coefs], columns=sim_coef_list.columns, index=['avg'])\n    \n    # Concatenate the original DataFrame with the average coefficients DataFrame\n    result_df = pd.concat([sim_coef_list, avg_coefs_df], ignore_index=False)\n    \n    return result_df, avg_coefs_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df, avg_arr= get_avg_coefs_with_df(sim_coef_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df.head(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_arr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df.head(100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n# def evaluate_logistic_regression(X_test, y_test, coefs):\n#     \"\"\"\n#     Evaluate logistic regression performance on test data using provided coefficients,\n#     and plot relevant metrics including the sigmoid function, confusion matrix, ROC curve.\n    \n#     Parameters:\n#     X_test (pd.DataFrame or np.ndarray): Test feature data.\n#     y_test (pd.Series or np.ndarray): True labels for the test data.\n#     coefs (np.ndarray): Coefficients including the intercept as the last element.\n    \n#     Returns:\n#     dict: Performance metrics including accuracy, precision, recall, F1 score, and ROC AUC.\n#     \"\"\"\n    \n#     X_test = X_test.apply(pd.to_numeric, errors='coerce')\n    \n#     # Extract feature coefficients and intercept\n#     intercept = coefs[-1]\n#     feature_coefs = coefs[:-1]\n    \n#     # Compute logits (linear combination of features and coefficients)\n#     logits = np.dot(X_test, feature_coefs) + intercept\n    \n#     y_vals = []\n    \n#     for i in logits:\n#         if i > 0:\n#             y_vals.append(1)\n#         else:\n#             y_vals.append(0)\n    \n#     # Compute predicted probabilities using the logistic function\n#     probabilities = 1 / (1 + np.exp(-logits))\n    \n#     # Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n#     predictions = (probabilities > 0.5).astype(int)\n    \n#     accuracy = accuracy_score(y_test, predictions) \n    \n#     n = len(X_test)\n#     mse = 1 - accuracy\n#     num_params = len(X_test.columns)\n    \n#     aic = n * math.log(mse) + 2 * num_params\n    \n#     # Calculate performance metrics\n#     metrics = {\n#         'Accuracy': accuracy,\n#         'Precision': precision_score(y_test, predictions),\n#         'Recall': recall_score(y_test, predictions),\n#         'F1 Score': f1_score(y_test, predictions),\n#         'ROC AUC': roc_auc_score(y_test, probabilities),\n#         'AIC Score': aic,\n#     }\n    \n#     # Plot the sigmoid function and overlay computed z values\n#     z = logits  # z values based on the linear combination\n#     sigmoid = 1 / (1 + np.exp(-z))\n    \n#     # Plot Sigmoid Function\n#     plt.figure(figsize=(8, 4))\n#     z_values = np.linspace(-7.5, 5, 400)\n#     sigmoid_curve = 1 / (1 + np.exp(-z_values))\n#     plt.plot(z_values, sigmoid_curve, label='Sigmoid Function Curve')\n#     plt.scatter(z, y_vals, color='red', s=50, alpha=0.7, label='Computed Sigmoid Values')\n#     plt.title('Sigmoid Function with Computed Values')\n#     plt.xlabel('Logits (z)')\n#     plt.ylabel('Probability')\n#     plt.grid(True)\n#     plt.legend()\n#     plt.show()\n    \n#     # Plot confusion matrix\n#     cm = confusion_matrix(y_test, predictions)\n#     cm_df = pd.DataFrame(cm, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n#     plt.figure(figsize=(8, 6))\n#     sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n#     plt.title('Confusion Matrix')\n#     plt.xlabel('Predicted Labels')\n#     plt.ylabel('True Labels')\n#     plt.show()\n    \n#     # Plot ROC curve\n#     fpr, tpr, _ = roc_curve(y_test, probabilities)\n#     auc = roc_auc_score(y_test, probabilities)\n#     plt.figure(figsize=(8, 4))\n#     plt.plot(fpr, tpr, color='blue', lw=2, label=\"auc=\"+str(auc))\n#     plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n#     plt.title('ROC Curve')\n#     plt.xlabel('False Positive Rate')\n#     plt.ylabel('True Positive Rate')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.show()\n    \n#     return metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics = evaluate_logistic_regression(X_test, Y_test, avg_arr)\n# print(metrics)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def mod_create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2, feature_cols):\n    \n#     random_nc = pd.DataFrame()\n#     X_train = pd.DataFrame()\n#     X_test = pd.DataFrame()\n#     Y_train = pd.DataFrame()\n#     Y_test = pd.DataFrame()\n    \n#     random_indices = get_random_indices(8,len(non_cancerous1))\n    \n#     random_nc = non_cancerous1.iloc[random_indices]\n    \n#     full_train_set = pd.concat([cancerous1,random_nc])\n    \n#     full_test_set = pd.concat([cancerous2,non_cancerous2])\n    \n#     X_train = full_train_set[feature_cols]\n#     Y_train = pd.concat([Y_train,full_train_set['Dx']])\n    \n#     X_test = full_test_set[feature_cols]\n#     Y_test = pd.concat([Y_test,full_test_set['Dx']])\n    \n#     return X_train.reset_index(drop=True), Y_train.reset_index(drop=True), X_test.reset_index(drop=True), Y_test.reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def mod_run_simulation(sim_len, df_total, feature_cols):\n    \n#     sim_coef_list = pd.DataFrame()\n    \n#     cancerous1, cancerous2, non_cancerous1, non_cancerous2 = split_data(df_total)\n    \n#     for i in range(sim_len):\n        \n#         X_train, Y_train, X_test, Y_test = mod_create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2, feature_cols) \n        \n#         coef_list = get_coefs(X_train,Y_train)\n        \n#         sim_coef_list = pd.concat([coef_list,sim_coef_list])\n        \n#     return sim_coef_list.reset_index(drop=True), X_test, Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n# def mod_evaluate_logistic_regression(X_test, y_test, coefs):\n    \n#     \"\"\"\n#     Evaluate logistic regression performance on test data using provided coefficients,\n#     and plot relevant metrics including the sigmoid function, confusion matrix, ROC curve.\n    \n#     Parameters:\n#     X_test (pd.DataFrame or np.ndarray): Test feature data.\n#     y_test (pd.Series or np.ndarray): True labels for the test data.\n#     coefs (np.ndarray): Coefficients including the intercept as the last element.\n    \n#     Returns:\n#     dict: Performance metrics including accuracy, precision, recall, F1 score, and ROC AUC.\n#     \"\"\"\n    \n#     X_test = X_test.apply(pd.to_numeric, errors='coerce')\n    \n#     # Extract feature coefficients and intercept\n#     intercept = coefs[-1]\n#     feature_coefs = coefs[:-1]\n    \n#     # Compute logits (linear combination of features and coefficients)\n#     logits = np.dot(X_test, feature_coefs) + intercept\n    \n#     # Compute predicted probabilities using the logistic function\n#     probabilities = 1 / (1 + np.exp(-logits))\n    \n#     # Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n#     predictions = (probabilities > 0.5).astype(int)\n    \n#     acc = accuracy_score(y_test, predictions)\n    \n#     n = len(X_test)\n#     mse = 1 - acc\n#     num_params = len(X_test.columns)\n    \n#     # Calculate performance metrics\n#     metrics = {\n#         'Accuracy': acc,\n#         'Precision': precision_score(y_test, predictions),\n#         'Recall': recall_score(y_test, predictions),\n#         'F1 Score': f1_score(y_test, predictions),\n#         'ROC AUC': roc_auc_score(y_test, probabilities),\n#         'AIC Score': calculate_AIC(n,mse,num_params)\n#     }\n    \n#     return metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import itertools\n# def finding_optimal_attributes(df_total, sim_len, max_cols):\n    \n#     feature_cols = ['Age', 'Number of sexual partners', 'First sexual intercourse',\n#        'Num of pregnancies', 'Smokes', 'Smokes (years)', 'Smokes (packs/year)',\n#        'Hormonal Contraceptives', 'Hormonal Contraceptives (years)', 'IUD',\n#        'IUD (years)', 'STDs', 'STDs (number)', 'STDs:condylomatosis',\n#        'STDs:cervical condylomatosis', 'STDs:vaginal condylomatosis',\n#        'STDs:vulvo-perineal condylomatosis', 'STDs:syphilis',\n#        'STDs:pelvic inflammatory disease', 'STDs:genital herpes',\n#        'STDs:molluscum contagiosum', 'STDs:AIDS', 'STDs:HIV',\n#        'STDs:Hepatitis B', 'STDs:HPV', 'STDs: Number of diagnosis',\n#        'Dx:Cancer', 'Dx:CIN', 'Dx:HPV', 'Hinselmann', 'Schiller',\n#        'Citology', 'Biopsy']\n\n#     best_combination = None\n#     best_accuracy = 0\n#     best_aic = float('inf')\n\n#     results = []\n\n#     for L in range(1, max_cols):\n#         for subset in itertools.combinations(feature_cols, L):\n            \n#             df_optimized_x = df_total[list(subset)].reset_index(drop=True)\n#             df_optimized_y = df_total[['Dx']].reset_index(drop=True)\n#             df_optimized = pd.concat([df_optimized_x, df_optimized_y], axis=1)\n\n#             sim_coef_list, X_test, Y_test = mod_run_simulation(sim_len, df_optimized, list(subset))\n\n#             avg_df, avg_arr = get_avg_coefs_with_df(sim_coef_list)\n\n#             metrics = mod_evaluate_logistic_regression(X_test, Y_test, avg_arr)\n\n#             results.append({\n#                 'features': subset,\n#                 'accuracy': metrics['Accuracy'],\n#                 'aic': metrics['AIC Score']\n#             })\n\n#             if metrics['Accuracy'] >= best_accuracy and metrics['AIC Score'] <= best_aic:\n#                 best_accuracy = metrics['Accuracy']\n#                 best_aic = metrics['AIC Score']\n#                 best_combination = subset\n\n#     results_df = pd.DataFrame(results)\n#     return results_df, best_combination, best_accuracy, best_aic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# corr_matrix = df_cleaned.astype(float).corr()\n# corr_matrix.head(35)\n# corr_matrix.style.background_gradient(cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# # Select upper triangle of correlation matrix\n# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n# # Find index of feature columns with correlation greater than 0.95\n# to_drop = [column for column in upper.columns if any(abs(upper[column]) >=0.8)]\n\n# to_drop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_2 = df_cleaned.drop(to_drop, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_len = 100\n# df_total = df_cleaned_2\n# feature_cols = df_total.columns\n# sim_coef_list_2, X_test_2, Y_test_2 = mod_run_simulation(sim_len, df_total, feature_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df_2, avg_arr_2 = get_avg_coefs_with_df(sim_coef_list_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics_2 = evaluate_logistic_regression(X_test_2, Y_test_2, avg_arr_2)\n# print(metrics_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_std_of_coef(avg_df):\n    # Compute the standard deviation of each column, excluding the last row and the last column\n    std_coefs = avg_df.iloc[:-1, :-1].std()\n    \n    # Convert the resulting Series to a NumPy array\n    std_coefs_array = std_coefs.to_numpy()\n    \n    # Create a DataFrame from the standard deviation coefficients\n    std_coefs_df = pd.DataFrame([std_coefs], columns=avg_df.columns[:-1], index=['std'])\n    \n    # Append a column for the intercept with NaN as it was excluded\n    std_coefs_df[avg_df.columns[-1]] = float('nan')\n    \n    # Concatenate the original DataFrame with the standard deviation coefficients DataFrame\n    result_df = pd.concat([avg_df, std_coefs_df], ignore_index=False)\n    \n    return result_df, std_coefs_array, std_coefs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_test, std_test_array = get_std_of_coef(avg_df_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_test.head(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def coef_divided_std(std_df):\n    # Divide the second-to-last row by the last row and add the result as a new row\n    div_result = std_df.iloc[:-1,-2] / std_df.iloc[:-1,-1]\n    div_result.name = 'div'\n    \n    # Create a DataFrame from the div_result Series\n    div_result_df = pd.DataFrame([div_result])\n    \n    # Concatenate the original DataFrame with the div_result DataFrame\n    result_df = pd.concat([std_df, div_result_df], ignore_index=False)\n    \n    # Convert the result DataFrame to a NumPy array\n    std_coefs_array = result_df.to_numpy()\n    \n    return result_df, std_coefs_array","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df, std_coefs_array = coef_divided_std(std_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df.head(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test_2.columns[21]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_3 = df_cleaned_2.drop(X_test_2.columns[21], axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_len = 100\n# df_total = df_cleaned_3\n# feature_cols = df_total.columns\n# sim_coef_list_3, X_test_3, Y_test_3 = mod_run_simulation(sim_len, df_total, feature_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df_3, avg_arr_3 = get_avg_coefs_with_df(sim_coef_list_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics_3 = evaluate_logistic_regression(X_test_3, Y_test_3, avg_arr_3)\n# print(metrics_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_test_2, std_test_array_2 = get_std_of_coef(avg_df_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df_2, std_coefs_array_2 = coef_divided_std(std_test_2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_3.columns[12]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_4 = df_cleaned_3.drop(df_cleaned_3.columns[12],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_len = 100\n# df_total = df_cleaned_4\n# feature_cols = df_total.columns\n# sim_coef_list_4, X_test_4, Y_test_4 = mod_run_simulation(sim_len, df_total, feature_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df_4, avg_arr_4 = get_avg_coefs_with_df(sim_coef_list_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics_4 = evaluate_logistic_regression(X_test_4, Y_test_4, avg_arr_4)\n# print(metrics_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_test_3, std_test_array_3 = get_std_of_coef(avg_df_4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df_2, std_coefs_array_2 = coef_divided_std(std_test_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df_2.head(200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# std_coef_df_2['x13']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_4[df_cleaned_4.columns[12]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_cleaned_5 = df_cleaned_4.drop('STDs:vaginal condylomatosis',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_len = 100\n# df_total = df_cleaned_5\n# feature_cols = df_total.columns\n# sim_coef_list_5, X_test_5, Y_test_5 = mod_run_simulation(sim_len, df_total, feature_cols)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# avg_df_5, avg_arr_5 = get_avg_coefs_with_df(sim_coef_list_5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics_5 = evaluate_logistic_regression(X_test_5, Y_test_5, avg_arr_5)\n# print(metrics_5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mod_create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2, feature_cols, diagnosis_col_name):\n    \n    feature_cols = feature_cols.drop(diagnosis_col_name)\n    \n    random_nc = pd.DataFrame()\n    X_train = pd.DataFrame()\n    X_test = pd.DataFrame()\n    Y_train = pd.DataFrame()\n    Y_test = pd.DataFrame()\n    \n    random_indices = get_random_indices(8,len(non_cancerous1))\n    \n    random_nc = non_cancerous1.iloc[random_indices]\n    \n    full_train_set = pd.concat([cancerous1,random_nc])\n    \n    full_test_set = pd.concat([cancerous2,non_cancerous2])\n    \n    X_train = full_train_set[feature_cols]\n    Y_train = pd.concat([Y_train,full_train_set['Dx']])\n    \n    X_test = full_test_set[feature_cols]\n    Y_test = pd.concat([Y_test,full_test_set['Dx']])\n    \n    return X_train.reset_index(drop=True), Y_train.reset_index(drop=True), X_test.reset_index(drop=True), Y_test.reset_index(drop=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mod_run_simulation(sim_len, df_total, feature_cols, diagnosis_col_name):\n    \n    sim_coef_list = pd.DataFrame()\n    \n    cancerous1, cancerous2, non_cancerous1, non_cancerous2 = split_data(df_total)\n    \n    for i in range(sim_len):\n        \n        X_train, Y_train, X_test, Y_test = mod_create_train_test_set(cancerous1, cancerous2, non_cancerous1, non_cancerous2, feature_cols, diagnosis_col_name) \n        \n        coef_list = get_coefs(X_train,Y_train)\n        \n        sim_coef_list = pd.concat([coef_list,sim_coef_list])\n        \n    return sim_coef_list.reset_index(drop=True), X_test, Y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\ndef mod_evaluate_logistic_regression(X_test, y_test, coefs):\n    \"\"\"\n    Evaluate logistic regression performance on test data using provided coefficients,\n    and plot relevant metrics including the sigmoid function, confusion matrix, ROC curve.\n    \n    Parameters:\n    X_test (pd.DataFrame or np.ndarray): Test feature data.\n    y_test (pd.Series or np.ndarray): True labels for the test data.\n    coefs (np.ndarray): Coefficients including the intercept as the last element.\n    \n    Returns:\n    dict: Performance metrics including accuracy, precision, recall, F1 score, and ROC AUC.\n    \"\"\"\n    \n    X_test = X_test.apply(pd.to_numeric, errors='coerce')\n    \n    # Extract feature coefficients and intercept\n    intercept = coefs[-1]\n    feature_coefs = coefs[:-1]\n    \n    # Compute logits (linear combination of features and coefficients)\n    logits = np.dot(X_test, feature_coefs) + intercept\n    \n    y_vals = []\n    \n    for i in logits:\n        if i > 0:\n            y_vals.append(1)\n        else:\n            y_vals.append(0)\n    \n    # Compute predicted probabilities using the logistic function\n    probabilities = 1 / (1 + np.exp(-logits))\n    \n    # Convert probabilities to binary predictions using a threshold (e.g., 0.5)\n    predictions = (probabilities > 0.5).astype(int)\n    \n    accuracy = accuracy_score(y_test, predictions) \n    \n    n = len(X_test)\n    mse = 1 - accuracy\n    num_params = len(X_test.columns)\n    \n    aic = n * math.log(mse) + 2 * num_params\n    \n    # Calculate performance metrics\n    metrics = {\n        'Accuracy': accuracy,\n        'Precision': precision_score(y_test, predictions),\n        'Recall': recall_score(y_test, predictions),\n        'F1 Score': f1_score(y_test, predictions),\n        'ROC AUC': roc_auc_score(y_test, probabilities),\n        'AIC Score': aic,\n        'Columns' : len(X_test.columns)\n    }\n    \n    # Plot the sigmoid function and overlay computed z values\n    z = logits  # z values based on the linear combination\n    sigmoid = 1 / (1 + np.exp(-z))\n    \n    # Plot Sigmoid Function\n    plt.figure(figsize=(8, 4))\n    z_values = np.linspace(-7.5, 5, 400)\n    sigmoid_curve = 1 / (1 + np.exp(-z_values))\n    plt.plot(z_values, sigmoid_curve, label='Sigmoid Function Curve')\n    plt.scatter(z, y_vals, color='red', s=50, alpha=0.7, label='Computed Sigmoid Values')\n    plt.title('Sigmoid Function with Computed Values')\n    plt.xlabel('Logits (z)')\n    plt.ylabel('Probability')\n    plt.grid(True)\n    plt.legend()\n    plt.show()\n    \n    # Plot confusion matrix\n    cm = confusion_matrix(y_test, predictions)\n    cm_df = pd.DataFrame(cm, index=['Actual Negative', 'Actual Positive'], columns=['Predicted Negative', 'Predicted Positive'])\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.show()\n    \n    # Plot ROC curve\n    fpr, tpr, _ = roc_curve(y_test, probabilities)\n    auc = roc_auc_score(y_test, probabilities)\n    plt.figure(figsize=(8, 4))\n    plt.plot(fpr, tpr, color='blue', lw=2, label=\"auc=\"+str(auc))\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.title('ROC Curve')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n    \n    return metrics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_metrics(sim_len, df_total, feature_cols, diagnosis_col_name):\n    \n    sim_coef_list, X_test, Y_test =  mod_run_simulation(sim_len, df_total, feature_cols, diagnosis_col_name)\n        \n    avg_df, avg_arr= get_avg_coefs_with_df(sim_coef_list)\n        \n    metrics = mod_evaluate_logistic_regression(X_test, Y_test, avg_arr)\n    \n    print('Metrics: ', metrics)\n    \n    return avg_df\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_high_corr(df_name):\n    \n    corr_matrix = df_name.astype(float).corr()\n    corr_matrix.style.background_gradient(cmap='coolwarm')\n    \n    # Select upper triangle of correlation matrix\n    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n\n    # Find index of feature columns with correlation greater than 0.95\n    to_drop = [column for column in upper.columns if any(abs(upper[column]) >=0.8)]\n\n    return to_drop","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_min_col(std_coef_df): \n    \n    row_to_search = std_coef_df.iloc[-1, :-1]\n    \n    # Find the index of the minimum value in the specified row\n    min_col_index = row_to_search.idxmin()\n    \n    return min_col_index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def best_model_simulation(total_col_len, sim_len, df_total, diagnosis_col_name):\n    \n    avg_coef = pd.DataFrame()\n    df_mod_temp = pd.DataFrame()\n    min_col = 0\n    \n    for i in range(0,total_col_len):\n        \n        if(i == 0):\n            \n            model_metrics(sim_len, df_total, df_total.columns, diagnosis_col_name)\n            \n        elif(i == 1):\n            \n            high_corr_cols = get_high_corr(df_total)\n            \n            df_mod_temp = df_total.drop(to_drop, axis=1)\n            \n            avg_coef = model_metrics(sim_len, df_mod_temp, df_mod_temp.columns, diagnosis_col_name)\n        else:\n            \n            std, std_array, std_coefs = get_std_of_coef(avg_coef)\n        \n            std_coef_df, std_coefs_array = coef_divided_std(std)\n        \n            min_col = get_min_col(std_coef_df)\n        \n#             df_mod_temp.drop(df_mod_temp.columns[min_col],axis=1,inplace=true) # figure how to get index of min\n        \n#             avg_coef = model_metrics(sim_len, df_mod_temp, df_mod_temp.columns, diagnosis_col_name)\n    return std_coefs,std ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std_coefs, std = best_model_simulation(3, 100, df_cleaned, 'Dx')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std_coefs.head(1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"std.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n#df_optimized_x.head(668)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n#df_optimized_y.head(668)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n#df_optimized.head(690)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test\n#df_optimized[df_optimized['Dx']==1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Example usage:\n# results_df, best_combination, best_accuracy, best_aic = finding_optimal_attributes(df_cleaned, 100)\n# print(results_df)\n# print(f\"Best combination: {best_combination}, Accuracy: {best_accuracy}, AIC: {best_aic}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sim_len = 100\n# max_cols = 20\n\n# results_df, best_combination, best_accuracy, best_aic = finding_optimal_attributes(df_cleaned, 1, 5)\n# print(results_df)\n# print(f\"Best combination: {best_combination}, Accuracy: {best_accuracy}, AIC: {best_aic}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}